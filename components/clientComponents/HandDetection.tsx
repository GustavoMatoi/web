"use client"; // Diretiva do Next.js para indicar que este √© um componente client-side
import { useEffect, useRef, useState } from "react"; // Importa hooks do React para efeitos, refer√™ncias e estado
import { Arquivo } from "../../types/types";

// Tipos para as bibliotecas externas
interface Point { // Interface que define um ponto 2D
  x: number; // Coordenada X do ponto
  y: number; // Coordenada Y do ponto
}

interface Keypoint extends Point { // Interface que estende Point para representar pontos-chave da m√£o
  score?: number; // Pontua√ß√£o de confian√ßa da detec√ß√£o (opcional)
  name?: string; // Nome do ponto-chave (opcional)
}

interface Hand { // Interface que representa uma m√£o detectada
  keypoints: Keypoint[]; // Array de pontos-chave da m√£o
  handedness: string; // Indica se √© m√£o esquerda ou direita
  score: number; // Pontua√ß√£o de confian√ßa da detec√ß√£o da m√£o
}

interface TensorFlow { // Interface para a biblioteca TensorFlow.js
  setBackend: (backend: string) => Promise<void>; // M√©todo para definir o backend de processamento
}

interface HandPoseDetection { // Interface para a biblioteca de detec√ß√£o de poses de m√£o
  SupportedModels: { // Modelos suportados pela biblioteca
    MediaPipeHands: string; // Modelo MediaPipe Hands
  };
  createDetector: ( // M√©todo para criar um detector
    model: string, // Nome do modelo a ser usado
    config: DetectorConfig // Configura√ß√£o do detector
  ) => Promise<HandDetector>; // Retorna uma Promise com o detector criado
}

interface DetectorConfig { // Interface para configura√ß√£o do detector
  runtime: string; // Runtime a ser usado (mediapipe, tfjs, etc.)
  modelType: string; // Tipo do modelo (lite, full, etc.)
  solutionPath: string; // Caminho para os arquivos da solu√ß√£o
}

interface HandDetector { // Interface para o detector de m√£os
  estimateHands: (video: HTMLVideoElement) => Promise<Hand[]>; // M√©todo que estima as m√£os em um v√≠deo
}

// Extens√£o da interface Window para incluir as bibliotecas
declare global { // Declara√ß√£o global para estender tipos existentes
  interface Window { // Estende a interface Window do navegador
    tf: TensorFlow; // Adiciona a propriedade tf (TensorFlow.js)
    handPoseDetection: HandPoseDetection; // Adiciona a propriedade handPoseDetection
  }
}

// Tipos para o componente
interface FingertipPoints { // Interface para mapear √≠ndices de pontas dos dedos para cores
  [key: number]: string; // Chave num√©rica (√≠ndice do dedo) para valor string (cor)
}

type ProximityPair = [number, number]; // Tipo que representa um par de √≠ndices para compara√ß√£o de proximidade

const HandDetection = ({arquivo, transferirArquivo}: {arquivo: string, transferirArquivo: () => void }) => { // Componente funcional React para detec√ß√£o de gestos de m√£o
  const videoRef = useRef<HTMLVideoElement>(null); // Refer√™ncia para o elemento de v√≠deo
  const canvasRef = useRef<HTMLCanvasElement>(null); // Refer√™ncia para o elemento canvas
  const [isLoading, setIsLoading] = useState<boolean>(true); // Estado para controlar se est√° carregando
  const [error, setError] = useState<string | null>(null); // Estado para armazenar mensagens de erro
  const [isGrabbing, setIsGrabbing] = useState<boolean>(false); // Estado para indicar se est√° fazendo gesto de pegar
  const [videoReady, setVideoReady] = useState<boolean>(false); // Estado para indicar se o v√≠deo est√° pronto

  // Define as pontas dos dedos (√≠ndices dos pontos no modelo) e a cor para cada um
  const fingertipPoints: FingertipPoints = { // Objeto que mapeia √≠ndices dos dedos para suas cores
    4: "#56321A", // Polegar - cor marrom
    8: "#1A5637", // Indicador - cor verde escura
    12: "#425194", // M√©dio - cor azul
    16: "#942E8F", // Anelar - cor roxo
    20: "#948E14", // Mindinho - cor amarelo escuro
  };

  // Define os pares de dedos que devem ser comparados para medir dist√¢ncia
  const proximityPairs: ProximityPair[] = [ // Array de pares de √≠ndices para verificar proximidade
    [4, 8], // Polegar e indicador
    [4, 12], // Polegar e m√©dio
    [4, 16], // Polegar e anelar
    [4, 20], // Polegar e mindinho
    [8, 12], // Indicador e m√©dio
    [12, 16], // M√©dio e anelar
    [16, 20], // Anelar e mindinho
    [8, 20], // Indicador e mindinho
  ];

  // Fun√ß√£o que calcula a dist√¢ncia euclidiana entre dois pontos
  const getDistance = (p1: Point, p2: Point): number => { // Fun√ß√£o que recebe dois pontos e retorna a dist√¢ncia
    const dx = p1.x - p2.x; // Calcula a diferen√ßa em X
    const dy = p1.y - p2.y; // Calcula a diferen√ßa em Y
    return Math.sqrt(dx * dx + dy * dy); // Retorna a dist√¢ncia euclidiana usando teorema de Pit√°goras
  };

  // Fun√ß√£o que ativa a c√¢mera
  const setupCamera = async (): Promise<HTMLVideoElement | undefined> => { // Fun√ß√£o ass√≠ncrona para configurar a c√¢mera
    try { // Bloco try para capturar erros
      const stream = await navigator.mediaDevices.getUserMedia({ // Solicita acesso aos dispositivos de m√≠dia
        video: { // Configura√ß√µes do v√≠deo
          width: { ideal: 640 }, // Largura ideal de 640 pixels
          height: { ideal: 480 }, // Altura ideal de 480 pixels
          facingMode: "user", // Usa a c√¢mera frontal
        },
        audio: false, // N√£o solicita √°udio
      });

      if (videoRef.current) { // Verifica se a refer√™ncia do v√≠deo existe
        videoRef.current.srcObject = stream; // Define o stream como fonte do v√≠deo
        // Force video to load and play
        videoRef.current.load(); // For√ßa o carregamento do v√≠deo
        return new Promise((resolve, reject) => { // Retorna uma Promise
          if (videoRef.current) { // Verifica novamente se a refer√™ncia existe
            videoRef.current.onloadedmetadata = async () => { // Evento disparado quando metadados s√£o carregados
              try { // Bloco try interno
                await videoRef.current!.play(); // Inicia a reprodu√ß√£o do v√≠deo
                console.log("V√≠deo carregado e reproduzindo"); // Log de sucesso
                setVideoReady(true); // Marca o v√≠deo como pronto
                resolve(videoRef.current!); // Resolve a Promise com o elemento de v√≠deo
              } catch (playError) { // Captura erros de reprodu√ß√£o
                reject(playError); // Rejeita a Promise com o erro
              }
            };
            videoRef.current.onerror = () => { // Evento de erro do v√≠deo
              reject(new Error("Erro ao carregar o v√≠deo")); // Rejeita com erro customizado
            };
          }
        });
      }
    } catch (err) { // Captura erros da solicita√ß√£o de m√≠dia
      const errorMessage = // Cria mensagem de erro
        err instanceof Error ? err.message : "Erro desconhecido"; // Verifica se √© uma inst√¢ncia de Error
      throw new Error("Erro ao acessar a c√¢mera: " + errorMessage); // Lan√ßa erro customizado
    }
  };

  // Carrega os scripts necess√°rios dinamicamente
  const loadScripts = (): Promise<void> => { // Fun√ß√£o que carrega scripts externos dinamicamente
    return new Promise((resolve, reject) => { // Retorna uma Promise
      // Verifica se as bibliotecas j√° est√£o carregadas
      if (window.tf && window.handPoseDetection) { // Se as bibliotecas j√° existem no window
        resolve(); // Resolve imediatamente
        return; // Sai da fun√ß√£o
      }

      let scriptsLoaded = 0; // Contador de scripts carregados
      const totalScripts = 4; // Total de scripts a serem carregados

      const checkAllLoaded = (): void => { // Fun√ß√£o para verificar se todos os scripts foram carregados
        scriptsLoaded++; // Incrementa o contador
        if (scriptsLoaded === totalScripts) { // Se todos os scripts foram carregados
          resolve(); // Resolve a Promise
        }
      };

      const createScript = (src: string, errorMsg: string): void => { // Fun√ß√£o auxiliar para criar elementos script
        const script = document.createElement("script"); // Cria elemento script
        script.src = src; // Define o source do script
        script.onload = checkAllLoaded; // Define callback de sucesso
        script.onerror = () => reject(new Error(errorMsg)); // Define callback de erro
        document.head.appendChild(script); // Adiciona o script ao head do documento
      };

      // TensorFlow.js Core
      createScript( // Carrega o core do TensorFlow.js
        "https://unpkg.com/@tensorflow/tfjs-core@3.7.0/dist/tf-core.js", // URL do script
        "Erro ao carregar TensorFlow.js Core" // Mensagem de erro
      );

      // TensorFlow.js WebGL Backend
      createScript( // Carrega o backend WebGL do TensorFlow.js
        "https://unpkg.com/@tensorflow/tfjs-backend-webgl@3.7.0/dist/tf-backend-webgl.js", // URL do script
        "Erro ao carregar TensorFlow.js WebGL" // Mensagem de erro
      );

      // Hand Pose Detection
      createScript( // Carrega a biblioteca de detec√ß√£o de poses de m√£o
        "https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection@2.0.0/dist/hand-pose-detection.js", // URL do script
        "Erro ao carregar Hand Pose Detection" // Mensagem de erro
      );

      // MediaPipe Hands
      createScript( // Carrega a biblioteca MediaPipe Hands
        "https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/hands.min.js", // URL do script
        "Erro ao carregar MediaPipe" // Mensagem de erro
      );
    });
  };

  useEffect(() => { // Hook useEffect para executar efeitos colaterais
    // S√≥ executa no cliente
    if (typeof window === "undefined") return; // Verifica se est√° no ambiente do navegador

    let animationFrame: number; // Vari√°vel para armazenar o ID do frame de anima√ß√£o
    let detector: HandDetector; // Vari√°vel para o detector de m√£os
    let isGrabbingState = false; // Estado local para controle do gesto de pegar

    const initializeDetection = async (): Promise<void> => { // Fun√ß√£o ass√≠ncrona para inicializar a detec√ß√£o
      try { // Bloco try para capturar erros
        setIsLoading(true); // Define estado de carregamento como true
        setError(null); // Limpa mensagens de erro
        console.log("Iniciando detec√ß√£o..."); // Log de in√≠cio

        // Primeiro configura a c√¢mera
        const video = await setupCamera(); // Aguarda a configura√ß√£o da c√¢mera
        console.log("C√¢mera configurada:", video); // Log de sucesso da c√¢mera

        // Carrega as bibliotecas
        console.log("Carregando bibliotecas..."); // Log de carregamento
        await loadScripts(); // Aguarda o carregamento dos scripts

        // Aguarda um pouco para garantir que as bibliotecas estejam dispon√≠veis
        await new Promise((resolve) => setTimeout(resolve, 1000)); // Espera 1 segundo

        // Define o backend do TensorFlow.js
        console.log("Configurando TensorFlow..."); // Log de configura√ß√£o
        await window.tf.setBackend("webgl"); // Define WebGL como backend

        // Aguarda um pouco para o v√≠deo estabilizar
        await new Promise((resolve) => setTimeout(resolve, 1000)); // Espera mais 1 segundo

        // Cria o detector
        console.log("Criando detector..."); // Log de cria√ß√£o do detector
        const model = window.handPoseDetection.SupportedModels.MediaPipeHands; // Obt√©m o modelo MediaPipe
        detector = await window.handPoseDetection.createDetector(model, { // Cria o detector
          runtime: "mediapipe", // Define runtime como mediapipe
          modelType: "lite", // Usa modelo lite (mais r√°pido)
          solutionPath: "https://cdn.jsdelivr.net/npm/@mediapipe/hands", // Caminho para os arquivos do MediaPipe
        });

        console.log("Detector criado, iniciando detec√ß√£o..."); // Log de sucesso
        setIsLoading(false); // Define carregamento como false

        // Inicia a detec√ß√£o
        detectHands(); // Chama a fun√ß√£o de detec√ß√£o
      } catch (err) { // Captura erros
        const errorMessage = // Cria mensagem de erro
          err instanceof Error ? err.message : "Erro desconhecido"; // Verifica tipo do erro
        console.error("Erro na inicializa√ß√£o:", err); // Log do erro
        setError(errorMessage); // Define mensagem de erro no estado
        setIsLoading(false); // Para o carregamento
      }
    };

    // Fun√ß√£o de detec√ß√£o cont√≠nua
    const detectHands = async (): Promise<void> => { // Fun√ß√£o ass√≠ncrona para detec√ß√£o cont√≠nua
      if (!detector || !videoRef.current || !canvasRef.current) return; // Verifica se todos os elementos necess√°rios existem

      const threshold = 45; // Define limiar de dist√¢ncia para proximidade (em pixels)
      const canvas = canvasRef.current; // Obt√©m refer√™ncia do canvas
      const ctx = canvas.getContext("2d"); // Obt√©m contexto 2D do canvas
      if (!ctx) return; // Verifica se o contexto existe

      try { // Bloco try para capturar erros
        const hands = await detector.estimateHands(videoRef.current); // Detecta m√£os no frame atual

        // Limpa o canvas
        ctx.clearRect(0, 0, canvas.width, canvas.height); // Limpa todo o canvas

        // Desenha c√≠rculo indicando o threshold (usando o polegar como refer√™ncia)
        if (hands.length > 0) { // Se pelo menos uma m√£o foi detectada
          const keypoints = hands[0].keypoints; // Obt√©m pontos-chave da primeira m√£o
          for (const indexStr of Object.keys(fingertipPoints)) { // Itera sobre os √≠ndices das pontas dos dedos
            const index = parseInt(indexStr, 10); // Converte string para n√∫mero
            const point = keypoints[index]; // Obt√©m o ponto correspondente
            if (point) { // Se o ponto existe
              ctx.beginPath(); // Inicia novo caminho de desenho
              ctx.strokeStyle = "rgba(255, 255, 255, 0.5)"; // Define cor branca transl√∫cida
              ctx.lineWidth = 2; // Define espessura da linha
              ctx.arc(point.x, point.y, threshold, 0, 2 * Math.PI); // Desenha c√≠rculo com raio igual ao threshold
              ctx.stroke(); // Aplica o tra√ßado
            }
          }
        }

        // Processa cada m√£o detectada
        for (const hand of hands) { // Itera sobre todas as m√£os detectadas
          const keypoints = hand.keypoints; // Obt√©m pontos-chave da m√£o atual

          // Desenha os pontos das pontas dos dedos
          for (const index of Object.keys(fingertipPoints)) { // Itera sobre os √≠ndices das pontas
            const numIndex = parseInt(index, 10); // Converte para n√∫mero
            const point = keypoints[numIndex]; // Obt√©m o ponto
            if (point) { // Se o ponto existe
              ctx.beginPath(); // Inicia novo caminho
              ctx.arc(point.x, point.y, 8, 0, 2 * Math.PI); // Desenha c√≠rculo pequeno (raio 8)
              ctx.fillStyle = fingertipPoints[numIndex]; // Define cor espec√≠fica do dedo
              ctx.fill(); // Preenche o c√≠rculo
            }
          }

          // Conta pares de dedos pr√≥ximos
          let paresProximos = 0; // Contador de pares pr√≥ximos
          for (const [a, b] of proximityPairs) { // Itera sobre os pares definidos
            const p1 = keypoints[a]; // Obt√©m primeiro ponto do par
            const p2 = keypoints[b]; // Obt√©m segundo ponto do par
            if (p1 && p2) { // Se ambos os pontos existem
              const d = getDistance(p1, p2); // Calcula dist√¢ncia entre os pontos
              if (d < threshold) { // Se a dist√¢ncia √© menor que o limiar
                paresProximos++; // Incrementa contador
              }
            }
          }

          // L√≥gica do gesto
          if (!isGrabbingState && paresProximos >= 1) { // Se n√£o estava pegando e h√° pelo menos 1 par pr√≥ximo
            isGrabbingState = true; // Marca como pegando
            setIsGrabbing(true); // Atualiza estado React
            alert(`Arquivo detectado para transfer√™ncia: ${arquivo}`)
            console.log("üñêÔ∏è Gesto final: pegar (iniciado)"); // Log do gesto
          } else if (isGrabbingState && paresProximos === 0) { // Se estava pegando e n√£o h√° pares pr√≥ximos
            isGrabbingState = false; // Marca como n√£o pegando
            transferirArquivo()
            setIsGrabbing(false); // Atualiza estado React
            console.log("üôå Gesto final: soltar (liberado)"); // Log do gesto
          }
        }
      } catch (err) { // Captura erros na detec√ß√£o
        console.error("Erro na detec√ß√£o:", err); // Log do erro
      }

      // Pr√≥ximo frame
      animationFrame = requestAnimationFrame(detectHands); // Agenda pr√≥xima execu√ß√£o
    };

    initializeDetection(); // Chama inicializa√ß√£o

    // Cleanup
    return () => { // Fun√ß√£o de limpeza do useEffect
      if (animationFrame) { // Se h√° frame de anima√ß√£o ativo
        cancelAnimationFrame(animationFrame); // Cancela o frame
      }
      if (videoRef.current && videoRef.current.srcObject) { // Se h√° v√≠deo ativo
        const stream = videoRef.current.srcObject as MediaStream; // Obt√©m stream
        const tracks = stream.getTracks(); // Obt√©m todas as trilhas
        tracks.forEach((track) => track.stop()); // Para cada trilha
      }
    };
  }, []); // Array de depend√™ncias vazio (executa apenas uma vez)

  const handleRetry = (): void => { // Fun√ß√£o para tentar novamente
    window.location.reload(); // Recarrega a p√°gina
  };

  if (error) { // Se h√° erro
    return ( // Retorna interface de erro
      <div className="flex items-center justify-center min-h-screen bg-gray-900 text-white"> {/* Container principal centralizado */}
        <div className="text-center"> {/* Container do conte√∫do centralizado */}
          <h2 className="text-xl font-bold mb-4">Erro</h2> {/* T√≠tulo do erro */}
          <p className="text-red-400">{error}</p> {/* Mensagem de erro em vermelho */}
          <button // Bot√£o para tentar novamente
            onClick={handleRetry} // Manipulador de clique
            className="mt-4 px-4 py-2 bg-blue-600 rounded hover:bg-blue-700 transition-colors" // Classes de estilo
          >
            Tentar Novamente {/* Texto do bot√£o */}
          </button>
        </div>
      </div>
    );
  }

  return ( // Retorna interface principal
    <div className="flex flex-col items-center justify-center min-h-screen bg-black"> {/* Container principal */}
      {isLoading && ( // Se est√° carregando
        <div className="absolute z-20 text-white text-center"> {/* Overlay de carregamento */}
          <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-white mx-auto mb-4"></div> {/* Spinner de carregamento */}
          <p>Carregando detec√ß√£o de gestos...</p> {/* Texto de carregamento */}
          {!videoReady && ( // Se v√≠deo n√£o est√° pronto
            <p className="text-sm mt-2">Aguardando permiss√£o da c√¢mera...</p> // Texto adicional
          )}
        </div>
      )}

      <div className="relative border-2 border-gray-600 rounded-lg overflow-hidden"> {/* Container do v√≠deo */}
        <video // Elemento de v√≠deo
          ref={videoRef} // Refer√™ncia React
          width="640" // Largura
          height="480" // Altura
          autoPlay // Reprodu√ß√£o autom√°tica
          playsInline // Reprodu√ß√£o inline (m√≥vel)
          muted // Sem √°udio
          className="block" // Classe CSS
          style={{ // Estilos inline
            transform: "scaleX(-1)", // Espelha horizontalmente
            backgroundColor: "#000", // Fundo preto
            minHeight: "480px", // Altura m√≠nima
            minWidth: "640px", // Largura m√≠nima
          }}
        />
        <canvas // Elemento canvas para desenhar
          ref={canvasRef} // Refer√™ncia React
          width="640" // Largura
          height="480" // Altura
          className="absolute top-0 left-0 pointer-events-none" // Classes CSS (posicionamento absoluto)
          style={{ transform: "scaleX(-1)" }} // Espelha para coincidir com o v√≠deo
        />
      </div>

      <div className="mt-4 text-center"> {/* Container de informa√ß√µes */}
        <div // Status do gesto
          className={`text-2xl font-bold ${ // Classes base + condicionais
            isGrabbing ? "text-red-400" : "text-green-400" // Cor baseada no estado
          }`}
        >
          {isGrabbing ? "üñêÔ∏è Pegando" : "üôå Solto"} {/* Texto baseado no estado */}
        </div>
        <p className="text-gray-400 mt-2"> {/* Instru√ß√£o para o usu√°rio */}
          Mova sua m√£o em frente √† c√¢mera para detectar gestos
        </p>
      </div>
    </div>
  );
};

export default HandDetection; // Exporta o componente como padr√£o